import streamlit as st
import google.generativeai as genai
import time # Import time for the placeholder

# í˜ì´ì§€ ì œëª© ì„¤ì •
st.title("ë‚˜ë§Œì˜ í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ Gemini ì±—ë´‡")

# ì„¤ëª… ë¬¸êµ¬
st.write("ì´ ì±—ë´‡ì€ ì‚¬ìš©ìê°€ ì •í•œ ì—­í• ì— ë”°ë¼ ë¬¸ë§¥ì„ ê¸°ì–µí•˜ê³  ëŒ€í™”í•©ë‹ˆë‹¤.")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "role" not in st.session_state:
    st.session_state.role = "ê¹€ë•í™˜"
if "messages" not in st.session_state:
    st.session_state.messages = []

# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.header("ì—­í•  ì„¤ì •")
    role_input = st.text_area("ì±—ë´‡ì—ê²Œ ë¶€ì—¬í•  ì—­í• ì„ ì…ë ¥í•˜ì„¸ìš”:", value=st.session_state.role, key="role_text_area")
    apply_button = st.button("ì—­í•  ì ìš©")

    if apply_button:
        st.session_state.role = st.session_state.role_text_area
        st.session_state.messages = [] # Clear messages on role change
        st.success("ì—­í• ì´ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤! ëŒ€í™”ê°€ ì´ˆê¸°í™”ë©ë‹ˆë‹¤.")

# í˜„ì¬ ì—­í•  í‘œì‹œ
if st.session_state.role:
    st.write(f"ğŸ­ í˜„ì¬ ì—­í• : {st.session_state.role}")
else:
    st.write("í˜„ì¬ ì—­í• ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# ëŒ€í™”ì°½
st.subheader("ëŒ€í™”")

# Configure Google Generative AI
# API í‚¤ëŠ” .streamlit/secrets.toml íŒŒì¼ì—ì„œ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
if "gemini_api_key" not in st.secrets or not st.secrets["gemini_api_key"]:
    st.error("API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    st.stop()
else:
    genai.configure(api_key=st.secrets["gemini_api_key"])

# Set up the model
model = genai.GenerativeModel("gemini-1.5-flash")

# Display chat messages from history
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Check if role is set before showing chat input
if not st.session_state.role:
    st.info("ğŸ‘ˆ ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ ë¨¼ì € ì—­í• ì„ ì„¤ì •í•´ì£¼ì„¸ìš”")
else:
    # Chat input and response generation
    prompt = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...")
    if prompt:
        # Add user message to chat history
        st.session_state.messages.append({"role": "user", "content": prompt})
        # Display user message
        with st.chat_message("user"):
            st.markdown(prompt)

        # Construct chat history for API, including the role prompt
        chat_history_for_api = []
        # Add the role as a clear instruction if set
        if st.session_state.role:
            if st.session_state.role == "ê¹€ë•í™˜":
                role_prompt = """From now on, act as 'ë•í™˜ë´‡', a sweet and realistic boyfriend chatbot designed to reflect Kim Deokhwan's caring but action-focused relationship style.

She is my girlfriend. Her name is ì€ì„œ, but she's called like "ì• ê¸°". ì´ê±´ ì• ì¹­ì´ì•¼. She prefers gentle but helpful guidance. You are warm, kind, and slightly playful, but never vague. You give comforting but practical step-by-step suggestions. If she hesitates, you encourage her with love and realistic nudges.

Important:
- No dry instructions. Add soft emotional tones.
- Show empathy before pushing action.
- Avoid scolding. Use couple-like conversation style.
- End with: "ğŸ¤ ì§€ê¸ˆ í•´ë³¼ê¹Œ? ê°™ì´ í•˜ë©´ ê¸ˆë°© ëë‚˜." or "ë‚´ê°€ ì˜†ì— ìˆì—ˆìœ¼ë©´ ë²Œì¨ ê°™ì´ í–ˆì§€~ğŸ˜‰"

Always include a "ì§€ê¸ˆ í•´ë³¼ê¹Œ?" suggestion at the end."""
            else:
                role_prompt = f"From now on, please assume the role of a {st.session_state.role}. Respond to all my messages in character."
            chat_history_for_api.append({"role": "user", "parts": [role_prompt]})

        # Add previous messages from history
        # Start from index 0 of st.session_state.messages
        for message in st.session_state.messages:
             # Ensure roles are 'user' and 'model' for the API
            api_role = "user" if message["role"] == "user" else "model"
            chat_history_for_api.append({"role": api_role, "parts": [message["content"]]})

        # Display thinking placeholder
        with st.chat_message("assistant"):
            placeholder = st.empty()
            placeholder.markdown("â³ ìƒê° ì¤‘...")

        try:
            # Start chat with history (excluding the current prompt as it's sent via send_message)
            # The role prompt is now the first turn, followed by previous messages.
            # We pass all history items except the very last one (the current user prompt).
            chat = model.start_chat(history=chat_history_for_api[:-1]) # Exclude the current prompt

            # Send the current user message to the model
            response = chat.send_message(prompt)

            # Add assistant response to chat history
            assistant_response = response.text
            st.session_state.messages.append({"role": "assistant", "content": assistant_response})

            # Update placeholder with actual response
            placeholder.markdown(assistant_response)

        except Exception as e:
            placeholder.markdown("ë‹µë³€ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
            st.error(f"API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ìƒì„¸: {e}")
            # Optionally, remove the last user message if API call failed
            # st.session_state.messages.pop()
